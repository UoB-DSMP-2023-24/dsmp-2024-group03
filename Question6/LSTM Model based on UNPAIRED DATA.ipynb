{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35b5f8e-cd4d-43a8-946a-65d89c9e7f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complex.id', 'gene', 'cdr3', 'v.segm', 'j.segm', 'species', 'mhc.a', 'mhc.b', 'mhc.class', 'antigen.epitope', 'antigen.gene', 'antigen.species', 'reference.id', 'method', 'meta', 'cdr3fix', 'vdjdb.score', 'web.method', 'web.method.seq', 'web.cdr3fix.nc', 'web.cdr3fix.unmp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "##------------------读取文件----------------------------------------------------\n",
    "# 定义文件路径\n",
    "file_path = 'vdjdb.txt'  # 将 'your_file.txt' 替换为你的文件路径\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # 读取文件的第一行，获取所有的信息变量名\n",
    "    header = file.readline().strip().split('\\t')\n",
    "    tcr_data = [dict(zip(header, line.strip().split('\\t'))) for line in file]\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ca186-7dcf-4fec-b5fc-68944f538946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------清洗第一步，提取所需属性-----------------------------------\n",
    "selected_data = [{'cdr3': entry['cdr3'],\n",
    "                  'antigen.epitope': entry['antigen.epitope'],\n",
    "                  'vdjdb.score': entry['vdjdb.score']}\n",
    "                 for entry in tcr_data]\n",
    "##------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---清洗第二步，转化为数据集，并删去重复元素,同时删除可信度低的行-----------------------\n",
    "df_raw = pd.DataFrame(selected_data)\n",
    "df_clean = df_raw[df_raw['vdjdb.score'] != '0']\n",
    "df_clean = df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c8c997-8e52-447c-a75e-5df2fc791c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data= df_raw[df_raw['vdjdb.score'] == '0']\n",
    "neg_data = neg_data.reset_index(drop=True)\n",
    "pos_data=df_raw[df_raw['vdjdb.score'] != '0']\n",
    "pos_data = pos_data.reset_index(drop=True)\n",
    "num_positive_samples = len(pos_data)\n",
    "\n",
    "# 从阴性样本中随机抽取与阳性样本数量相同的样本\n",
    "neg_data_sampled = neg_data.sample(n=num_positive_samples, random_state=42)\n",
    "neg_data_sampled = neg_data_sampled.reset_index(drop=True)\n",
    "pos_data = pos_data.reset_index(drop=True)\n",
    "neg_data_sampled['label']=0\n",
    "pos_data['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a162d0ff-9f5f-4026-a37c-6ee1c4cd33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = pd.concat([neg_data_sampled, pos_data], axis=0)\n",
    "balanced_dataset = balanced_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc8ca0a-08d3-417b-bf00-90e37a62f849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdr3</th>\n",
       "      <th>antigen.epitope</th>\n",
       "      <th>vdjdb.score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAVIGTTDSWGKLQF</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAFMMNYGGSQGNLIF</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASSGAGGEVFF</td>\n",
       "      <td>SYIGSINNI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAASSLYGQNFVF</td>\n",
       "      <td>LLWNGPMAV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARPPETQYF</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24823</th>\n",
       "      <td>CASSQGSGGNEQFF</td>\n",
       "      <td>FPQPEQPFPWQP</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24824</th>\n",
       "      <td>CAASVLYGSSNTGKLIF</td>\n",
       "      <td>QLQPFPQPELPY</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24825</th>\n",
       "      <td>CASSIVGSGGYNEQFF</td>\n",
       "      <td>QLQPFPQPELPY</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24826</th>\n",
       "      <td>CAPQGATNKLIF</td>\n",
       "      <td>PQQPFPQPEQPFP</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>CASSLGAGGQETQYF</td>\n",
       "      <td>PQQPFPQPEQPFP</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24828 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cdr3 antigen.epitope vdjdb.score  label\n",
       "0        CAVIGTTDSWGKLQF       KLGGALQAK           0      0\n",
       "1       CAFMMNYGGSQGNLIF       KLGGALQAK           0      0\n",
       "2           CASSGAGGEVFF       SYIGSINNI           0      0\n",
       "3          CAASSLYGQNFVF       LLWNGPMAV           0      0\n",
       "4             CARPPETQYF      ELAGIGILTV           0      0\n",
       "...                  ...             ...         ...    ...\n",
       "24823     CASSQGSGGNEQFF    FPQPEQPFPWQP           2      1\n",
       "24824  CAASVLYGSSNTGKLIF    QLQPFPQPELPY           2      1\n",
       "24825   CASSIVGSGGYNEQFF    QLQPFPQPELPY           2      1\n",
       "24826       CAPQGATNKLIF   PQQPFPQPEQPFP           2      1\n",
       "24827    CASSLGAGGQETQYF   PQQPFPQPEQPFP           2      1\n",
       "\n",
       "[24828 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e94e0e-13a4-44b3-8730-60ffd83f5a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的cdr3: CYSTWRLSCLLLCRDSAGAGSYQLTF\n",
      "最长cdr3的长度: 26\n",
      "最长的antigen_epitope: MTEYKLVVVGAVGVGKSALTIQLI\n",
      "最长antigen_epitope的长度: 24\n"
     ]
    }
   ],
   "source": [
    "##----------------接下来编码-------------------------------\n",
    "encoding_map = {'A': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'C': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'D': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'E': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'F': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'G': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'H': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'I': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'K': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'M': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'N': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                'S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                'T': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                'V': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                'W': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                'Y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
    "cdr3_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['cdr3']]\n",
    "antigen_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['antigen.epitope']]\n",
    "##独热码成功编辑，但是矩阵长度不一致\n",
    "longest_cdr3 = max(balanced_dataset['cdr3'], key=len)\n",
    "print(\"最长的cdr3:\", longest_cdr3)\n",
    "print(\"最长cdr3的长度:\", len(longest_cdr3))\n",
    "longest_antigen_epitope = max(balanced_dataset['antigen.epitope'], key=len)\n",
    "print(\"最长的antigen_epitope:\", longest_antigen_epitope)\n",
    "print(\"最长antigen_epitope的长度:\", len(longest_antigen_epitope))\n",
    "\n",
    "\n",
    "def padding_sequence(origin, sequence_length):\n",
    "    padded = np.zeros((sequence_length, 20))\n",
    "    padded[:len(origin)] = origin\n",
    "    return padded\n",
    "\n",
    "\n",
    "cdr3_encoded_padded = [padding_sequence(seq, len(longest_cdr3)) for seq in cdr3_encoded]\n",
    "antigen_encoded_padded = [padding_sequence(seq, len(longest_antigen_epitope)) for seq in antigen_encoded]\n",
    "cdr3_encoded_padded_flat = [seq.flatten() for seq in cdr3_encoded_padded]\n",
    "antigen_encoded_padded_flat = [seq.flatten() for seq in antigen_encoded_padded]\n",
    "balanced_dataset['cdr3_code'] = cdr3_encoded_padded_flat\n",
    "balanced_dataset['antigen_code'] = antigen_encoded_padded_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff98935-ba8e-4bff-8b1e-caee71e61777",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset['input'] = balanced_dataset.apply(lambda row: list(row['cdr3_code']) + list(row['antigen_code']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67a4eca-6a9b-4234-b8d8-c2871a70377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24828\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 将输入和输出数据转换为 PyTorch 张量\n",
    "input_tensor = torch.tensor(balanced_dataset['input'], dtype=torch.float32)\n",
    "input_tensor = input_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(balanced_dataset['label'])\n",
    "\n",
    "# 在输入数据中增加一个批次维度\n",
    "# 创建 TensorDataset\n",
    "dataset = TensorDataset(input_tensor, labels_tensor)\n",
    "print(len(dataset))\n",
    "# 定义训练集和测试集大小\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "# 创建 DataLoader\n",
    "batch_size = 32\n",
    "num_epochs = 5 \n",
    "\n",
    "# 创建训练集 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "# 创建测试集 DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da0a1f5a-1c9b-43d3-9c03-70cd4dcc60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1000, hidden_dim=128, num_layers=2, output_dim=1, dropout=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Extract the last time step output\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51c53d70-42b4-446a-bf4e-89f705db976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, labels):\n",
    "    pred = (prediction > 0.5).long()  # 将大于0.5的预测值设为1，小于等于0.5的设为0\n",
    "    rights = pred.eq(labels.view_as(pred)).sum().item()  # 计算正确预测的数量\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da780c8c-bcdf-4261-8a74-7aad8c354b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch:0 [0/19862 (0.00%)]\t损失:0.694416\t训练集准确率:50.00%\t测试集正确率:49.40%\n",
      "当前epoch:0 [3200/19862 (16.10%)]\t损失:0.325713\t训练集准确率:69.89%\t测试集正确率:74.43%\n",
      "当前epoch:0 [6400/19862 (32.21%)]\t损失:0.472149\t训练集准确率:72.87%\t测试集正确率:76.94%\n",
      "当前epoch:0 [9600/19862 (48.31%)]\t损失:0.399630\t训练集准确率:74.47%\t测试集正确率:77.39%\n",
      "当前epoch:0 [12800/19862 (64.41%)]\t损失:0.455890\t训练集准确率:75.22%\t测试集正确率:78.27%\n",
      "当前epoch:0 [16000/19862 (80.52%)]\t损失:0.262161\t训练集准确率:76.02%\t测试集正确率:78.67%\n",
      "当前epoch:0 [19200/19862 (96.62%)]\t损失:0.396234\t训练集准确率:76.35%\t测试集正确率:78.98%\n",
      "当前epoch:1 [0/19862 (0.00%)]\t损失:0.355119\t训练集准确率:87.50%\t测试集正确率:79.14%\n",
      "当前epoch:1 [3200/19862 (16.10%)]\t损失:0.358467\t训练集准确率:80.38%\t测试集正确率:79.02%\n",
      "当前epoch:1 [6400/19862 (32.21%)]\t损失:0.416996\t训练集准确率:80.50%\t测试集正确率:78.53%\n",
      "当前epoch:1 [9600/19862 (48.31%)]\t损失:0.415484\t训练集准确率:80.56%\t测试集正确率:79.26%\n",
      "当前epoch:1 [12800/19862 (64.41%)]\t损失:0.506485\t训练集准确率:80.51%\t测试集正确率:79.42%\n",
      "当前epoch:1 [16000/19862 (80.52%)]\t损失:0.529442\t训练集准确率:80.29%\t测试集正确率:79.24%\n",
      "当前epoch:1 [19200/19862 (96.62%)]\t损失:0.516874\t训练集准确率:80.11%\t测试集正确率:79.82%\n",
      "当前epoch:2 [0/19862 (0.00%)]\t损失:0.301616\t训练集准确率:84.38%\t测试集正确率:80.06%\n",
      "当前epoch:2 [3200/19862 (16.10%)]\t损失:0.362575\t训练集准确率:81.50%\t测试集正确率:79.48%\n",
      "当前epoch:2 [6400/19862 (32.21%)]\t损失:0.484605\t训练集准确率:81.08%\t测试集正确率:80.08%\n",
      "当前epoch:2 [9600/19862 (48.31%)]\t损失:0.400356\t训练集准确率:81.08%\t测试集正确率:80.31%\n",
      "当前epoch:2 [12800/19862 (64.41%)]\t损失:0.375215\t训练集准确率:80.87%\t测试集正确率:80.65%\n",
      "当前epoch:2 [16000/19862 (80.52%)]\t损失:0.522482\t训练集准确率:80.85%\t测试集正确率:79.80%\n",
      "当前epoch:2 [19200/19862 (96.62%)]\t损失:0.591930\t训练集准确率:80.86%\t测试集正确率:80.21%\n",
      "当前epoch:3 [0/19862 (0.00%)]\t损失:0.355270\t训练集准确率:87.50%\t测试集正确率:80.12%\n",
      "当前epoch:3 [3200/19862 (16.10%)]\t损失:0.326663\t训练集准确率:82.12%\t测试集正确率:80.67%\n",
      "当前epoch:3 [6400/19862 (32.21%)]\t损失:0.526610\t训练集准确率:81.76%\t测试集正确率:81.05%\n",
      "当前epoch:3 [9600/19862 (48.31%)]\t损失:0.308877\t训练集准确率:81.69%\t测试集正确率:80.35%\n",
      "当前epoch:3 [12800/19862 (64.41%)]\t损失:0.338822\t训练集准确率:81.71%\t测试集正确率:80.31%\n",
      "当前epoch:3 [16000/19862 (80.52%)]\t损失:0.444929\t训练集准确率:81.54%\t测试集正确率:79.20%\n",
      "当前epoch:3 [19200/19862 (96.62%)]\t损失:0.430561\t训练集准确率:81.57%\t测试集正确率:80.75%\n",
      "当前epoch:4 [0/19862 (0.00%)]\t损失:0.387525\t训练集准确率:84.38%\t测试集正确率:80.43%\n",
      "当前epoch:4 [3200/19862 (16.10%)]\t损失:0.363519\t训练集准确率:84.31%\t测试集正确率:81.13%\n",
      "当前epoch:4 [6400/19862 (32.21%)]\t损失:0.322996\t训练集准确率:83.24%\t测试集正确率:80.61%\n",
      "当前epoch:4 [9600/19862 (48.31%)]\t损失:0.427476\t训练集准确率:83.17%\t测试集正确率:80.53%\n",
      "当前epoch:4 [12800/19862 (64.41%)]\t损失:0.393876\t训练集准确率:83.28%\t测试集正确率:80.69%\n",
      "当前epoch:4 [16000/19862 (80.52%)]\t损失:0.306826\t训练集准确率:83.19%\t测试集正确率:80.79%\n",
      "当前epoch:4 [19200/19862 (96.62%)]\t损失:0.328424\t训练集准确率:82.93%\t测试集正确率:80.67%\n"
     ]
    }
   ],
   "source": [
    "##训练网络模型\n",
    "net = LSTM()\n",
    "##损失函数\n",
    "criterion = nn.BCELoss()\n",
    "##优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "##开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target.view(-1, 1).float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target.view(-1, 1).float())\n",
    "        train_rights.append(right)\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target.view(-1, 1).float())\n",
    "                val_rights.append(right)\n",
    "            # 计算准确率\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            print(\"当前epoch:{} [{}/{} ({:.2f}%)]\\t损失:{:.6f}\\t训练集准确率:{:.2f}%\\t测试集正确率:{:.2f}%\".format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100 * batch_idx / len(train_loader),\n",
    "                loss.item(),\n",
    "                100 * train_r[0] / train_r[1],\n",
    "                100 * val_r[0] / val_r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc1857-a33a-46ad-9f51-2c233129fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
