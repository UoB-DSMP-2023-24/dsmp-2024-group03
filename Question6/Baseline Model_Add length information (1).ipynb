{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c23c77ea-186c-4b18-8cdc-592dd074f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complex.id', 'gene', 'cdr3', 'v.segm', 'j.segm', 'species', 'mhc.a', 'mhc.b', 'mhc.class', 'antigen.epitope', 'antigen.gene', 'antigen.species', 'reference.id', 'method', 'meta', 'cdr3fix', 'vdjdb.score', 'web.method', 'web.method.seq', 'web.cdr3fix.nc', 'web.cdr3fix.unmp']\n",
      "                  TRA                   TRB antigen_epitope vdjdb.score  \\\n",
      "1       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEKGGL           2   \n",
      "2      CAVPSGAGSYQLTF   CASSFEPGQGFYSNQPQHF        FLKEKGGL           2   \n",
      "3         CAVKASGSRLT  CASSYEPGQVSHYSNQPQHF        FLKEKGGL           2   \n",
      "4       CAYRPPGTYKYIF        CASSALASLNEQFF        FLKEKGGL           2   \n",
      "5       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEQGGL           2   \n",
      "...               ...                   ...             ...         ...   \n",
      "30590   CMDEGGSNYKLTF         CASSVRSTDTQYF    PQPELPYPQPQL           0   \n",
      "30591     CSLYNNNDMRF         CASSLRYTDTQYF    PQPELPYPQPQL           0   \n",
      "30592   CALSTDSWGKLQF       CASSPGQGGDNEQFF   PQQPFPQPEQPFP           0   \n",
      "30593    CAPQGATNKLIF       CASSLGAGGQETQYF   PQQPFPQPEQPFP           2   \n",
      "30594  CLVGGSGGYNKLIF         CASSSTAQETQYF   PQQPFPQPEQPFP           0   \n",
      "\n",
      "           species  \n",
      "1      HomoSapiens  \n",
      "2      HomoSapiens  \n",
      "3      HomoSapiens  \n",
      "4      HomoSapiens  \n",
      "5      HomoSapiens  \n",
      "...            ...  \n",
      "30590  HomoSapiens  \n",
      "30591  HomoSapiens  \n",
      "30592  HomoSapiens  \n",
      "30593  HomoSapiens  \n",
      "30594  HomoSapiens  \n",
      "\n",
      "[30594 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件路径\n",
    "file_path = 'vdjdb.txt'  # 将 'your_file.txt' 替换为你的文件路径\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # 读取文件的第一行，获取所有的信息变量名\n",
    "    header = file.readline().strip().split('\\t')\n",
    "    tcr_data = [dict(zip(header, line.strip().split('\\t'))) for line in file]\n",
    "print(header)\n",
    "cdr3_dict = {}\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    cdr3 = row['cdr3']\n",
    "    # 将相同 complex.id 的 cdr3 拼接起来\n",
    "    if complex_id in cdr3_dict:\n",
    "        cdr3_dict[complex_id].append(cdr3)\n",
    "    else:\n",
    "        cdr3_dict[complex_id] = [cdr3]\n",
    "# 假设有一个包含 TCR 序列的 DataFrame\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    antigen_epitope = row['antigen.epitope']\n",
    "    vdjdb_score = row['vdjdb.score']\n",
    "    species=row['species']\n",
    "    # 将相同 complex.id 的 cdr3 拼接起来\n",
    "    if len(cdr3_dict[complex_id]) == 2:\n",
    "        cdr3_dict[complex_id].append(antigen_epitope)\n",
    "        cdr3_dict[complex_id].append(vdjdb_score)\n",
    "        cdr3_dict[complex_id].append(species)\n",
    "    else:\n",
    "        continue\n",
    "cdr3_dict.pop('0')\n",
    "##删除未配对的TCR\n",
    "df_cdr3 = pd.DataFrame(cdr3_dict)\n",
    "df_cdr3_trans = df_cdr3.transpose()\n",
    "names = ['TRA', 'TRB', 'antigen_epitope', 'vdjdb.score','species']\n",
    "df_cdr3_trans.columns = names\n",
    "print(df_cdr3_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "780bd739-21c1-4d2a-9cc7-d51db97762b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdr3_trans=df_cdr3_trans[df_cdr3_trans['species'] == 'HomoSapiens']\n",
    "neg_data= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '0']\n",
    "pos_data_1= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '1']\n",
    "pos_data_2= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '2']\n",
    "pos_data_3= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '3']\n",
    "# 复制 pos_data_2 的数据两次\n",
    "pos_data_2_copy = pos_data_2.copy()\n",
    "pos_data_2_copy = pd.concat([pos_data_2_copy] * 2, ignore_index=True)\n",
    "\n",
    "# 复制 pos_data_3 的数据三次\n",
    "pos_data_3_copy = pos_data_3.copy()\n",
    "pos_data_3_copy = pd.concat([pos_data_3_copy] * 3, ignore_index=True)\n",
    "\n",
    "# 将复制后的数据与 pos_data_1 拼接在一起\n",
    "pos_data = pd.concat([pos_data_1, pos_data_2_copy, pos_data_3_copy], ignore_index=True)\n",
    "# 确定阳性样本数量\n",
    "num_positive_samples = len(pos_data)\n",
    "\n",
    "# 从阴性样本中随机抽取与阳性样本数量相同的样本\n",
    "neg_data_sampled = neg_data.sample(n=num_positive_samples, random_state=42)\n",
    "neg_data_sampled = neg_data_sampled.reset_index(drop=True)\n",
    "pos_data = pos_data.reset_index(drop=True)\n",
    "neg_data_sampled['label']=0\n",
    "pos_data['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7401c43c-bbe0-41a8-ae72-ded46ed50688",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = pd.concat([neg_data_sampled, pos_data], axis=0)\n",
    "balanced_dataset = balanced_dataset.reset_index(drop=True)\n",
    "balanced_dataset['TRA_TRB_Combined'] = balanced_dataset[\"TRA\"] + balanced_dataset[\"TRB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b462459-2669-41a1-8df4-29f0c65e8cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的cdr3: CAGAFWQGAQKLVFCASSQAGQRLAGALNPTQSYNEQFF\n",
      "最长cdr3的长度: 39\n",
      "最长的antigen_epitope: MTEYKLVVVGAVGVGKSALTIQLI\n",
      "最长antigen_epitope的长度: 24\n"
     ]
    }
   ],
   "source": [
    "##----------------接下来编码-------------------------------\n",
    "encoding_map = {'A': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'C': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'D': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'E': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'F': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'G': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'H': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'I': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'K': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'M': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'N': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                'S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                'T': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                'V': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                'W': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                'Y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
    "cdr3_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['TRA_TRB_Combined']]\n",
    "antigen_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['antigen_epitope']]\n",
    "##独热码成功编辑，但是矩阵长度不一致\n",
    "longest_cdr3 = max(balanced_dataset['TRA_TRB_Combined'], key=len)\n",
    "print(\"最长的cdr3:\", longest_cdr3)\n",
    "print(\"最长cdr3的长度:\", len(longest_cdr3))\n",
    "longest_antigen_epitope = max(balanced_dataset['antigen_epitope'], key=len)\n",
    "print(\"最长的antigen_epitope:\", longest_antigen_epitope)\n",
    "print(\"最长antigen_epitope的长度:\", len(longest_antigen_epitope))\n",
    "\n",
    "\n",
    "def padding_sequence(origin, sequence_length):\n",
    "    padded = np.zeros((sequence_length, 20))\n",
    "    padded[:len(origin)] = origin\n",
    "    return padded\n",
    "\n",
    "\n",
    "cdr3_encoded_padded = [padding_sequence(seq, len(longest_cdr3)) for seq in cdr3_encoded]\n",
    "antigen_encoded_padded = [padding_sequence(seq, len(longest_antigen_epitope)) for seq in antigen_encoded]\n",
    "cdr3_encoded_padded_flat = [seq.flatten() for seq in cdr3_encoded_padded]\n",
    "cdr3_length=[len(seq) for seq in balanced_dataset['TRA_TRB_Combined']]\n",
    "cdr3_encoded_padded_flat_with_length = [np.concatenate((flat_seq, [seq_length])) for flat_seq, seq_length in zip(cdr3_encoded_padded_flat, cdr3_length)]\n",
    "antigen_encoded_padded_flat = [seq.flatten() for seq in antigen_encoded_padded]\n",
    "antigen_length=[len(seq) for seq in balanced_dataset['antigen_epitope']]\n",
    "antigen_encoded_padded_flat_with_length = [np.concatenate((flat_seq, [seq_length])) for flat_seq, seq_length in zip(antigen_encoded_padded_flat, antigen_length)]\n",
    "balanced_dataset['cdr3_code'] = cdr3_encoded_padded_flat_with_length\n",
    "balanced_dataset['antigen_code'] =antigen_encoded_padded_flat_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58b44ac8-2f77-401b-a7c8-73ea353afd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset['input'] = balanced_dataset.apply(lambda row: list(row['cdr3_code']) + list(row['antigen_code']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b2e05cf-f610-4a11-a73a-9d4362633e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分特征和目标变量\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(balanced_dataset['input'].tolist())  # cdr3和待选抗原作为特征\n",
    "y = np.array(balanced_dataset['label'].tolist())  # label做为标签\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d79a7caa-554a-4288-82e5-12c1d5e56a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9293966623876765\n",
      "Precision: 0.8960396039603961\n",
      "F1 Score: 0.9124133585381222\n",
      "Accuracy: 0.9133416458852868\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 初始化决策树模型\n",
    "decision_tree = DecisionTreeClassifier(random_state=22)\n",
    "\n",
    "# 在训练集上拟合模型\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ac49eb1-a8a8-42a9-9ee9-ed2043845b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9242618741976893\n",
      "Precision: 0.8674698795180723\n",
      "F1 Score: 0.8949658172778123\n",
      "Accuracy: 0.8946384039900249\n"
     ]
    }
   ],
   "source": [
    "##Logistic Regression Model\n",
    "# 使用逻辑回归模型进行分类\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 初始化逻辑回归模型\n",
    "logistic_regression = LogisticRegression(max_iter=1000,random_state=22)\n",
    "\n",
    "# 训练模型\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04d6aad5-c573-4282-8a32-e98a5d17f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9563543003851092\n",
      "Precision: 0.905224787363305\n",
      "F1 Score: 0.9300873907615481\n",
      "Accuracy: 0.9301745635910225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# RandomForestClassfier\n",
    "\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=200,max_depth=None, max_features='log2', min_samples_split=2,random_state=22)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# predict test\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a97319b4-c81d-4fc6-a77a-742d1f6dd2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.2785622593068036\n",
      "Precision: 0.9273504273504274\n",
      "F1 Score: 0.4284304047384009\n",
      "Accuracy: 0.6390274314214464\n"
     ]
    }
   ],
   "source": [
    "##Naive_bayes Model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 初始化朴素贝叶斯模型\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# 在训练集上拟合模型\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "539a8090-94cb-4929-8f9c-59c0f711e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.938382541720154\n",
      "Precision: 0.9103362391033624\n",
      "F1 Score: 0.9241466498103665\n",
      "Accuracy: 0.9251870324189526\n"
     ]
    }
   ],
   "source": [
    "#KNN Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 初始化KNN模型\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# 训练模型\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac20e92-37d1-4000-b77e-fb99b7eadc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
