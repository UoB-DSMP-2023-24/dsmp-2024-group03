{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8a6ee6-242c-426f-a041-8097239e60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complex.id', 'gene', 'cdr3', 'v.segm', 'j.segm', 'species', 'mhc.a', 'mhc.b', 'mhc.class', 'antigen.epitope', 'antigen.gene', 'antigen.species', 'reference.id', 'method', 'meta', 'cdr3fix', 'vdjdb.score', 'web.method', 'web.method.seq', 'web.cdr3fix.nc', 'web.cdr3fix.unmp']\n",
      "                  TRA                   TRB antigen_epitope vdjdb.score  \\\n",
      "1       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEKGGL           2   \n",
      "2      CAVPSGAGSYQLTF   CASSFEPGQGFYSNQPQHF        FLKEKGGL           2   \n",
      "3         CAVKASGSRLT  CASSYEPGQVSHYSNQPQHF        FLKEKGGL           2   \n",
      "4       CAYRPPGTYKYIF        CASSALASLNEQFF        FLKEKGGL           2   \n",
      "5       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEQGGL           2   \n",
      "...               ...                   ...             ...         ...   \n",
      "30590   CMDEGGSNYKLTF         CASSVRSTDTQYF    PQPELPYPQPQL           0   \n",
      "30591     CSLYNNNDMRF         CASSLRYTDTQYF    PQPELPYPQPQL           0   \n",
      "30592   CALSTDSWGKLQF       CASSPGQGGDNEQFF   PQQPFPQPEQPFP           0   \n",
      "30593    CAPQGATNKLIF       CASSLGAGGQETQYF   PQQPFPQPEQPFP           2   \n",
      "30594  CLVGGSGGYNKLIF         CASSSTAQETQYF   PQQPFPQPEQPFP           0   \n",
      "\n",
      "           species  \n",
      "1      HomoSapiens  \n",
      "2      HomoSapiens  \n",
      "3      HomoSapiens  \n",
      "4      HomoSapiens  \n",
      "5      HomoSapiens  \n",
      "...            ...  \n",
      "30590  HomoSapiens  \n",
      "30591  HomoSapiens  \n",
      "30592  HomoSapiens  \n",
      "30593  HomoSapiens  \n",
      "30594  HomoSapiens  \n",
      "\n",
      "[30594 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件路径\n",
    "file_path = 'vdjdb.txt'  # 将 'your_file.txt' 替换为你的文件路径\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # 读取文件的第一行，获取所有的信息变量名\n",
    "    header = file.readline().strip().split('\\t')\n",
    "    tcr_data = [dict(zip(header, line.strip().split('\\t'))) for line in file]\n",
    "print(header)\n",
    "cdr3_dict = {}\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    cdr3 = row['cdr3']\n",
    "    # 将相同 complex.id 的 cdr3 拼接起来\n",
    "    if complex_id in cdr3_dict:\n",
    "        cdr3_dict[complex_id].append(cdr3)\n",
    "    else:\n",
    "        cdr3_dict[complex_id] = [cdr3]\n",
    "# 假设有一个包含 TCR 序列的 DataFrame\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    antigen_epitope = row['antigen.epitope']\n",
    "    vdjdb_score = row['vdjdb.score']\n",
    "    species=row['species']\n",
    "    # 将相同 complex.id 的 cdr3 拼接起来\n",
    "    if len(cdr3_dict[complex_id]) == 2:\n",
    "        cdr3_dict[complex_id].append(antigen_epitope)\n",
    "        cdr3_dict[complex_id].append(vdjdb_score)\n",
    "        cdr3_dict[complex_id].append(species)\n",
    "    else:\n",
    "        continue\n",
    "cdr3_dict.pop('0')\n",
    "##删除未配对的TCR\n",
    "df_cdr3 = pd.DataFrame(cdr3_dict)\n",
    "df_cdr3_trans = df_cdr3.transpose()\n",
    "names = ['TRA', 'TRB', 'antigen_epitope', 'vdjdb.score','species']\n",
    "df_cdr3_trans.columns = names\n",
    "print(df_cdr3_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b946fc-0a70-43b3-ac89-9bb3650dd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdr3_trans=df_cdr3_trans[df_cdr3_trans['species'] == 'HomoSapiens']\n",
    "neg_data= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '0']\n",
    "pos_data_1= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '1']\n",
    "pos_data_2= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '2']\n",
    "pos_data_3= df_cdr3_trans[df_cdr3_trans['vdjdb.score'] == '3']\n",
    "# 复制 pos_data_2 的数据两次\n",
    "pos_data_2_copy = pos_data_2.copy()\n",
    "pos_data_2_copy = pd.concat([pos_data_2_copy] * 2, ignore_index=True)\n",
    "\n",
    "# 复制 pos_data_3 的数据三次\n",
    "pos_data_3_copy = pos_data_3.copy()\n",
    "pos_data_3_copy = pd.concat([pos_data_3_copy] * 3, ignore_index=True)\n",
    "\n",
    "# 将复制后的数据与 pos_data_1 拼接在一起\n",
    "pos_data = pd.concat([pos_data_1, pos_data_2_copy, pos_data_3_copy], ignore_index=True)\n",
    "# 确定阳性样本数量\n",
    "num_positive_samples = len(pos_data)\n",
    "\n",
    "# 从阴性样本中随机抽取与阳性样本数量相同的样本\n",
    "neg_data_sampled = neg_data.sample(n=num_positive_samples, random_state=42)\n",
    "neg_data_sampled = neg_data_sampled.reset_index(drop=True)\n",
    "pos_data = pos_data.reset_index(drop=True)\n",
    "neg_data_sampled['label']=0\n",
    "pos_data['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa760799-e72b-487e-8b35-ee43f6a7d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = pd.concat([neg_data_sampled, pos_data], axis=0)\n",
    "balanced_dataset = balanced_dataset.reset_index(drop=True)\n",
    "balanced_dataset['TRA_TRB_Combined'] = balanced_dataset[\"TRA\"] + balanced_dataset[\"TRB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91e44af-1b79-444a-946d-20afc572fc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的cdr3: CAGAFWQGAQKLVFCASSQAGQRLAGALNPTQSYNEQFF\n",
      "最长cdr3的长度: 39\n",
      "最长的antigen_epitope: MTEYKLVVVGAVGVGKSALTIQLI\n",
      "最长antigen_epitope的长度: 24\n"
     ]
    }
   ],
   "source": [
    "##----------------接下来编码-------------------------------\n",
    "encoding_map = {'A': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'C': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'D': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'E': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'F': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'G': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'H': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'I': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'K': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'M': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'N': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                'S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                'T': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                'V': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                'W': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                'Y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
    "cdr3_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['TRA_TRB_Combined']]\n",
    "antigen_encoded = [[encoding_map[char] for char in sequence] for sequence in balanced_dataset['antigen_epitope']]\n",
    "##独热码成功编辑，但是矩阵长度不一致\n",
    "longest_cdr3 = max(balanced_dataset['TRA_TRB_Combined'], key=len)\n",
    "print(\"最长的cdr3:\", longest_cdr3)\n",
    "print(\"最长cdr3的长度:\", len(longest_cdr3))\n",
    "longest_antigen_epitope = max(balanced_dataset['antigen_epitope'], key=len)\n",
    "print(\"最长的antigen_epitope:\", longest_antigen_epitope)\n",
    "print(\"最长antigen_epitope的长度:\", len(longest_antigen_epitope))\n",
    "\n",
    "\n",
    "def padding_sequence(origin, sequence_length):\n",
    "    padded = np.zeros((sequence_length, 20))\n",
    "    padded[:len(origin)] = origin\n",
    "    return padded\n",
    "\n",
    "\n",
    "cdr3_encoded_padded = [padding_sequence(seq, len(longest_cdr3)) for seq in cdr3_encoded]\n",
    "antigen_encoded_padded = [padding_sequence(seq, len(longest_antigen_epitope)) for seq in antigen_encoded]\n",
    "cdr3_encoded_padded_flat = [seq.flatten() for seq in cdr3_encoded_padded]\n",
    "cdr3_length=[len(seq) for seq in balanced_dataset['TRA_TRB_Combined']]\n",
    "cdr3_encoded_padded_flat_with_length = [np.concatenate((flat_seq, [seq_length])) for flat_seq, seq_length in zip(cdr3_encoded_padded_flat, cdr3_length)]\n",
    "antigen_encoded_padded_flat = [seq.flatten() for seq in antigen_encoded_padded]\n",
    "antigen_length=[len(seq) for seq in balanced_dataset['antigen_epitope']]\n",
    "antigen_encoded_padded_flat_with_length = [np.concatenate((flat_seq, [seq_length])) for flat_seq, seq_length in zip(antigen_encoded_padded_flat, antigen_length)]\n",
    "balanced_dataset['cdr3_code'] = cdr3_encoded_padded_flat_with_length\n",
    "balanced_dataset['antigen_code'] =antigen_encoded_padded_flat_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a281aee-3155-4c02-9aeb-d105af59bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset['input'] = balanced_dataset.apply(lambda row: list(row['cdr3_code']) + list(row['antigen_code']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52841d6-bffc-4135-863b-8fa24aba466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8020\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 将输入和输出数据转换为 PyTorch 张量\n",
    "input_tensor = torch.tensor(balanced_dataset['input'], dtype=torch.float32)\n",
    "input_tensor = input_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(balanced_dataset['label'])\n",
    "\n",
    "# 在输入数据中增加一个批次维度\n",
    "# 创建 TensorDataset\n",
    "dataset = TensorDataset(input_tensor, labels_tensor)\n",
    "print(len(dataset))\n",
    "# 定义训练集和测试集大小\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "# 创建 DataLoader\n",
    "batch_size = 32\n",
    "num_epochs = 5 \n",
    "\n",
    "# 创建训练集 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "# 创建测试集 DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58be9c02-2ebf-486f-848e-3a3f91237af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1262, hidden_dim=128, num_layers=2, output_dim=1, dropout=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Extract the last time step output\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e84ea2-2ffc-4ec1-bc9c-e1eccd699011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, labels):\n",
    "    pred = (prediction > 0.5).long()  # 将大于0.5的预测值设为1，小于等于0.5的设为0\n",
    "    rights = pred.eq(labels.view_as(pred)).sum().item()  # 计算正确预测的数量\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129ab4fb-e512-4ccf-a476-94155f76f0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch:0 [0/6416 (0.00%)]\t损失:0.691486\t训练集准确率:50.00%\t测试集正确率:47.88%\n",
      "当前epoch:0 [3200/6416 (49.75%)]\t损失:0.313158\t训练集准确率:76.33%\t测试集正确率:84.91%\n",
      "当前epoch:0 [6400/6416 (99.50%)]\t损失:0.276458\t训练集准确率:80.99%\t测试集正确率:86.53%\n",
      "当前epoch:1 [0/6416 (0.00%)]\t损失:0.274479\t训练集准确率:84.38%\t测试集正确率:87.47%\n",
      "当前epoch:1 [3200/6416 (49.75%)]\t损失:0.308867\t训练集准确率:89.88%\t测试集正确率:88.15%\n",
      "当前epoch:1 [6400/6416 (99.50%)]\t损失:0.212424\t训练集准确率:89.26%\t测试集正确率:88.59%\n",
      "当前epoch:2 [0/6416 (0.00%)]\t损失:0.149631\t训练集准确率:96.88%\t测试集正确率:88.65%\n",
      "当前epoch:2 [3200/6416 (49.75%)]\t损失:0.179725\t训练集准确率:90.84%\t测试集正确率:88.40%\n",
      "当前epoch:2 [6400/6416 (99.50%)]\t损失:0.139125\t训练集准确率:90.74%\t测试集正确率:88.34%\n",
      "当前epoch:3 [0/6416 (0.00%)]\t损失:0.326038\t训练集准确率:84.38%\t测试集正确率:88.53%\n",
      "当前epoch:3 [3200/6416 (49.75%)]\t损失:0.275104\t训练集准确率:92.05%\t测试集正确率:89.15%\n",
      "当前epoch:3 [6400/6416 (99.50%)]\t损失:0.060518\t训练集准确率:91.75%\t测试集正确率:89.34%\n",
      "当前epoch:4 [0/6416 (0.00%)]\t损失:0.203229\t训练集准确率:90.62%\t测试集正确率:89.40%\n",
      "当前epoch:4 [3200/6416 (49.75%)]\t损失:0.068493\t训练集准确率:93.75%\t测试集正确率:89.78%\n",
      "当前epoch:4 [6400/6416 (99.50%)]\t损失:0.081621\t训练集准确率:92.85%\t测试集正确率:89.53%\n"
     ]
    }
   ],
   "source": [
    "##训练网络模型\n",
    "net = LSTM()\n",
    "##损失函数\n",
    "criterion = nn.BCELoss()\n",
    "##优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "##开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target.view(-1, 1).float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target.view(-1, 1).float())\n",
    "        train_rights.append(right)\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target.view(-1, 1).float())\n",
    "                val_rights.append(right)\n",
    "            # 计算准确率\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            print(\"当前epoch:{} [{}/{} ({:.2f}%)]\\t损失:{:.6f}\\t训练集准确率:{:.2f}%\\t测试集正确率:{:.2f}%\".format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100 * batch_idx / len(train_loader),\n",
    "                loss.item(),\n",
    "                100 * train_r[0] / train_r[1],\n",
    "                100 * val_r[0] / val_r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fc160-4c31-435b-b80b-08f0c1758ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
