{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32f2e4f-a875-4817-90f7-113db12c7b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  TRA                   TRB antigen_epitope vdjdb.score\n",
      "1       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEKGGL           2\n",
      "2      CAVPSGAGSYQLTF   CASSFEPGQGFYSNQPQHF        FLKEKGGL           2\n",
      "3         CAVKASGSRLT  CASSYEPGQVSHYSNQPQHF        FLKEKGGL           2\n",
      "4       CAYRPPGTYKYIF        CASSALASLNEQFF        FLKEKGGL           2\n",
      "5       CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKEQGGL           2\n",
      "...               ...                   ...             ...         ...\n",
      "30590   CMDEGGSNYKLTF         CASSVRSTDTQYF    PQPELPYPQPQL           0\n",
      "30591     CSLYNNNDMRF         CASSLRYTDTQYF    PQPELPYPQPQL           0\n",
      "30592   CALSTDSWGKLQF       CASSPGQGGDNEQFF   PQQPFPQPEQPFP           0\n",
      "30593    CAPQGATNKLIF       CASSLGAGGQETQYF   PQQPFPQPEQPFP           2\n",
      "30594  CLVGGSGGYNKLIF         CASSSTAQETQYF   PQQPFPQPEQPFP           0\n",
      "\n",
      "[30594 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import colors\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件路径\n",
    "file_path = 'vdjdb.txt'  # 将 'your_file.txt' 替换为你的文件路径\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # 读取文件的第一行，获取所有的信息变量名\n",
    "    header = file.readline().strip().split('\\t')\n",
    "    tcr_data = [dict(zip(header, line.strip().split('\\t'))) for line in file]\n",
    "cdr3_dict = {}\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    cdr3 = row['cdr3']\n",
    "    # Splice together CDR3 with the same complex ID\n",
    "    if complex_id in cdr3_dict:\n",
    "        cdr3_dict[complex_id].append(cdr3)\n",
    "    else:\n",
    "        cdr3_dict[complex_id] = [cdr3]\n",
    "# There is a DataFrame containing the TCR sequence\n",
    "for row in tcr_data:\n",
    "    complex_id = row['complex.id']\n",
    "    antigen_epitope = row['antigen.epitope']\n",
    "    vdjdb_score = row['vdjdb.score']\n",
    "    # Splice together CDR3 with the same complex ID\n",
    "    if len(cdr3_dict[complex_id]) == 2:\n",
    "        cdr3_dict[complex_id].append(antigen_epitope)\n",
    "        cdr3_dict[complex_id].append(vdjdb_score)\n",
    "    else:\n",
    "        continue\n",
    "cdr3_dict.pop('0')\n",
    "##Delete unpaired TCRs\n",
    "df_cdr3 = pd.DataFrame(cdr3_dict)\n",
    "df_cdr3_trans = df_cdr3.transpose()\n",
    "names = ['TRA', 'TRB', 'antigen_epitope', 'vdjdb.score']\n",
    "df_cdr3_trans.columns = names\n",
    "print(df_cdr3_trans)\n",
    "##The first step is to read out the paired data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa630f49-8a42-42e8-a663-4374032515d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are (3,) categories of data in the current dataset\n",
      "              TRA                   TRB antigen_epitope vdjdb.score  \\\n",
      "0   CIVRAPGRADMRF  CASSYLPGQGDHYSNQPQHF        FLKETGGL           2   \n",
      "1  CAVPSGAGSYQLTF   CASSFEPGQGFYSNQPQHF        FLKETGGL           2   \n",
      "2     CAVKASGSRLT  CASSYEPGQVSHYSNQPQHF        FLKETGGL           2   \n",
      "3     CAYRSAFKLTF       CAWSVPLGRREKLFF       YVLDHLIVV           3   \n",
      "4  CLVGGDNQGGKLIF        CASSQRQGGNTIYF    PQPELPYPQPQL           2   \n",
      "5     CIVYNNNDMRF         CASSIRSTDTQYF    PQPELPYPQPQL           2   \n",
      "6     CIVFNDYKLSF         CASSFRSTDTQYF    PQPELPYPQPQL           2   \n",
      "7      CIALNARLMF         CASSLRATDTQYF    PQPELPYPQPQL           2   \n",
      "\n",
      "                    TRA_TRB_Combined  \n",
      "0  CIVRAPGRADMRFCASSYLPGQGDHYSNQPQHF  \n",
      "1  CAVPSGAGSYQLTFCASSFEPGQGFYSNQPQHF  \n",
      "2    CAVKASGSRLTCASSYEPGQVSHYSNQPQHF  \n",
      "3         CAYRSAFKLTFCAWSVPLGRREKLFF  \n",
      "4       CLVGGDNQGGKLIFCASSQRQGGNTIYF  \n",
      "5           CIVYNNNDMRFCASSIRSTDTQYF  \n",
      "6           CIVFNDYKLSFCASSFRSTDTQYF  \n",
      "7            CIALNARLMFCASSLRATDTQYF  \n"
     ]
    }
   ],
   "source": [
    "df_clean = df_cdr3_trans[df_cdr3_trans['vdjdb.score'] != '0']\n",
    "#df_clean = df_clean.drop_duplicates()\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean['TRA_TRB_Combined'] = df_clean[\"TRA\"] + df_clean[\"TRB\"]\n",
    "specific_antigen_epitopes = ['PQPELPYPQPQL', 'FLKETGGL','YVLDHLIVV']\n",
    "df_clean = df_clean[df_clean['antigen_epitope'].isin(specific_antigen_epitopes)]\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "print(\"There are {} categories of data in the current dataset\".format(np.shape(df_clean['antigen_epitope'].unique())))\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8481e66-7ce8-44c4-8625-024c9961d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Edit Distance\n",
    "def ED(str_1, str_2):\n",
    "    m = len(str_1)\n",
    "    n = len(str_2)\n",
    "    # Initializes the dynamic programming matrix with sizes m+1 and n+1 respectively\n",
    "    Distance = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "    for i in range(n + 1):\n",
    "        Distance[0][i] = i\n",
    "    #\n",
    "    for j in range(m + 1):\n",
    "        Distance[j][0] = j\n",
    "    # Initialize the first row and column of the matrix\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            distance_delete = Distance[i - 1][j] + 1\n",
    "            distance_add = Distance[i][j - 1] + 1\n",
    "            if str_1[i - 1] == str_2[j - 1]:\n",
    "                distance_change = Distance[i - 1][j - 1]\n",
    "            else:\n",
    "                distance_change = Distance[i - 1][j - 1] + 1\n",
    "            Distance[i][j] = min(distance_delete, distance_add, distance_change)\n",
    "    # Count the items from bottom to top\n",
    "    return Distance[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a44816-b5e1-44bd-9133-937d1554cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Jaccard Distance\n",
    "def jaccard_distance(str1, str2):\n",
    "    set1 = set(str1)\n",
    "    set2 = set(str2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return 1 - intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5da7c5a-5639-4d96-92b6-4deff9fef908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently,  7.000000 TCR3s have been calculated\n"
     ]
    }
   ],
   "source": [
    "Distance_Matrix_TRA = np.zeros((df_clean.shape[0], df_clean.shape[0]))\n",
    "Distance_Matrix_TRB = np.zeros((df_clean.shape[0], df_clean.shape[0]))\n",
    "Distance_Matrix_TRAandTRB = np.zeros((df_clean.shape[0], df_clean.shape[0]))\n",
    "for i in range(df_clean.shape[0]):\n",
    "    for j in range(df_clean.shape[0]):\n",
    "        Distance_Matrix_TRA[i][j] = jaccard_distance(df_clean['TRA'][i], df_clean['TRA'][j])\n",
    "        Distance_Matrix_TRB[i][j] = jaccard_distance(df_clean['TRB'][i], df_clean['TRB'][j])\n",
    "        Distance_Matrix_TRAandTRB[i][j] = jaccard_distance(df_clean['TRA_TRB_Combined'][i], df_clean['TRA_TRB_Combined'][j])\n",
    "    if i % 10 == 0:\n",
    "        print(\"Currently, {: 2f} TCR3s have been calculated\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdf009d-4dac-4c67-8dc4-068786f6090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "# Defining functions for clustering distance matrices\n",
    "def cluster_distance_matrix(distance_matrix,n_cluster=3):\n",
    "    # Initialize KMeans model\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    #Fitting distance matrix using KMeans model\n",
    "    kmeans.fit(distance_matrix)\n",
    "    #Obtain clustering labels\n",
    "    labels = kmeans.labels_\n",
    "    return labels\n",
    "def cluster_distance_matrix_2(distance_matrix, eps=1.0, min_samples=5):\n",
    "    #Create DBSCAN model\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    #Fitting distance matrix and clustering\n",
    "    clusters = dbscan.fit_predict(distance_matrix)\n",
    "    return clusters.tolist()\n",
    "def cluster_distance_matrix_3(distance_matrix):\n",
    "    mean_shift = MeanShift()\n",
    "    # Fitting and clustering data\n",
    "    mean_shift.fit(distance_matrix)\n",
    "    labels = mean_shift.labels_\n",
    "    return labels\n",
    "# #Cluster the distance matrix of TRA\n",
    "TRA_clusters = cluster_distance_matrix(Distance_Matrix_TRA)\n",
    "\n",
    "# #Cluster the distance matrix of TRB\n",
    "\n",
    "TRB_clusters=cluster_distance_matrix(Distance_Matrix_TRB)\n",
    "# #Cluster the distance matrix of TRAandTRB\n",
    "\n",
    "TRAandTRB_clusters=cluster_distance_matrix(Distance_Matrix_TRAandTRB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291c1cb0-aa36-49c7-98ce-948d2a18436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 2 1 2 1]\n",
      "[2 2 2 0 1 1 1 1]\n",
      "[2 1 1 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(TRA_clusters)\n",
    "print(TRB_clusters)\n",
    "print(TRAandTRB_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d33a41a-4ff8-47b7-ab73-dc2b7395657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAandTRB Adjusted Rand Index (ARI): 0.13043478260869565\n",
      "TRAandTRB Normalized Mutual Information (NMI): 0.4832741472564202\n",
      "TRA Adjusted Rand Index (ARI): 0.13043478260869565\n",
      "TRA Normalized Mutual Information (NMI): 0.4832741472564202\n",
      "TRB Adjusted Rand Index (ARI): 1.0\n",
      "TRB Normalized Mutual Information (NMI): 1.0\n"
     ]
    }
   ],
   "source": [
    "##Next, calculate the effectiveness of the algorithm\n",
    "unique_antigen_epitopes = df_clean['antigen_epitope'].unique()\n",
    "# Create a dictionary corresponding to a category\n",
    "label_mapping = {antigen_epitope: idx for idx, antigen_epitope in enumerate(unique_antigen_epitopes, start=0)}\n",
    "\n",
    "# Create a list of real categories\n",
    "true_labels = [label_mapping[epitope] for epitope in df_clean['antigen_epitope']]\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "##--------Clustering based on TRAandTRB----------------------------------------\n",
    "# ARI\n",
    "ARI_TRAandTRB = adjusted_rand_score(true_labels, TRAandTRB_clusters)\n",
    "# NMI\n",
    "NMI_TRAandTRB = normalized_mutual_info_score(true_labels, TRAandTRB_clusters)\n",
    "#ARI\n",
    "print(\"TRAandTRB Adjusted Rand Index (ARI):\", ARI_TRAandTRB)\n",
    "print(\"TRAandTRB Normalized Mutual Information (NMI):\", NMI_TRAandTRB)\n",
    "##-----------Clustering based on TRA------------------------------------------\n",
    "# ARI\n",
    "ARI_TRA = adjusted_rand_score(true_labels, TRA_clusters)\n",
    "# NMI\n",
    "NMI_TRA = normalized_mutual_info_score(true_labels, TRA_clusters)\n",
    "#ARI\n",
    "print(\"TRA Adjusted Rand Index (ARI):\", ARI_TRA)\n",
    "print(\"TRA Normalized Mutual Information (NMI):\", NMI_TRA)\n",
    "##----------------Clustering based on TRB-----------------------------------\n",
    "# ARI\n",
    "ARI_TRB = adjusted_rand_score(true_labels, TRB_clusters)\n",
    "# NMI\n",
    "NMI_TRB = normalized_mutual_info_score(true_labels, TRB_clusters)\n",
    "#ARI\n",
    "print(\"TRB Adjusted Rand Index (ARI):\", ARI_TRB)\n",
    "print(\"TRB Normalized Mutual Information (NMI):\", NMI_TRB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393da7da-8ff1-4a37-ba65-3ca826919e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
